### LeNet - 5
It was a neural network that for recognizing digits.
It was a 5 layers that broke down the input into a single layer. Used sigmod and tahn 

### AlexNet
Has similarities to LeNet but had more layers and used relu.

### VGG
Simplified NN. It was doubling the Conv filters but then used Pool Max to reduce. Reducing the width and height.

## ResNet

They are layers that feed their past layer into the next one.

They work because they are able to skip past possible over learned dense layers and then cause them to learn the identity matrix of the output.

Residual Layers